{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209001ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import streamlit as st\n",
    "import pickle\n",
    "import time\n",
    "import langchain\n",
    "from langchain import OpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.chains.qa_with_sources.loading import load_qa_with_sources_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289c9404",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load openAI api key\n",
    "os.environ['OPENAI_API_KEY'] = 'your openapi key here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c820941",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialise LLM with required params\n",
    "llm = OpenAI(temperature=0.9, max_tokens=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0b14d9",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97272918",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loaders = UnstructuredURLLoader(urls=[\n",
    "    \"https://www.moneycontrol.com/news/business/markets/wall-street-rises-as-tesla-soars-on-ai-optimism-11351111.html\",\n",
    "    \"https://www.moneycontrol.com/news/business/tata-motors-launches-punch-icng-price-starts-at-rs-7-1-lakh-11098751.html\"\n",
    "])\n",
    "data = loaders.load()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3bcec5",
   "metadata": {},
   "source": [
    "## (2) Split data to create chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c357fd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "# As data is of type documents we can directly use split_documents over split_text in order to get the chunks.\n",
    "docs = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9ddbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae34682",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049bfadd",
   "metadata": {},
   "source": [
    "## \n",
    "(3) Create embeddings for these chunks and save them to FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eecfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the embeddings of the chunks using openAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Pass the documents and embeddings inorder to create FAISS vector index\n",
    "vectorindex_openai = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bd09dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing vector index create in local\n",
    "file_path = \"vector_index.pkl\"\n",
    "with open(file_path, \"wb\") as f:\n",
    "    pickle.dump(vectorindex_openai, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841b123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if os.path.exists(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        vectorIndex = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778a4308",
   "metadata": {},
   "source": [
    "## \n",
    "(4) Retrieve similar embeddings for a given question and call LLM to retrieve final answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0958dbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RetrievalQAWithSourcesChain.from_llm(\n",
    "    llm=llm, retriever=vectorIndex.as_retriever())\n",
    "chain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
